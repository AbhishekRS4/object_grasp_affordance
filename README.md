# Object part grasp affordance

## Pretrained models used for vision tasks
* There are 2 base models. One with densenet-121 and another with resnet-18

## Instruction to run training
* To list training options
```
python3 src/train.py --help
```

## The dataset used for training
* [http://users.umiacs.umd.edu/~fer/affordance/part-affordance-dataset/](http://users.umiacs.umd.edu/~fer/affordance/part-affordance-dataset/)

## References
* [Learning to See before Learning to Act: Visual Pre-training for Manipulation](http://yenchenlin.me/vision2action/)
